
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <title> | JXCUSO4的博客</title>
    <meta name="author" content="JXCUSO4" />
    <meta name="description" content="" />
    <meta name="keywords" content="" />
    <meta
        name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"
    />
    <link rel="icon" href="/images/star.jpg" />
    <link rel="preconnect" href="https://s4.zstatic.net" />
<script src="https://s4.zstatic.net/ajax/libs/vue/3.3.7/vue.global.prod.min.js"></script>
<link rel="stylesheet" href="https://s4.zstatic.net/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
<link rel="preconnect" href="https://fonts.googleapis.cn" />
<link rel="preconnect" href="https://fonts.gstatic.cn" crossorigin />
<link
    rel="stylesheet"
    href="https://fonts.googleapis.cn/css2?family=Fira+Code:wght@400;500;600;700&family=Lexend:wght@400;500;600;700;800;900&family=Noto+Sans+SC:wght@400;500;600;700;800;900&display=swap"
/>
<script> const mixins = {}; </script>

<script src="https://polyfill.alicdn.com/v3/polyfill.min.js?features=default"></script>


<script src="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script src="https://s4.zstatic.net/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
<link
    rel="stylesheet"
    href="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/styles/github.min.css"
/>
<script src="/js/lib/highlight.js"></script>


<script src="https://s4.zstatic.net/ajax/libs/KaTeX/0.16.9/katex.min.js"></script>
<script src="https://s4.zstatic.net/ajax/libs/KaTeX/0.16.9/contrib/auto-render.min.js"></script>
<link rel="stylesheet" href="https://s4.zstatic.net/ajax/libs/KaTeX/0.16.9/katex.min.css" />
<script src="/js/lib/math.js"></script>


<script src="/js/lib/preview.js"></script>









<link rel="stylesheet" href="/css/main.css" />

<meta name="generator" content="Hexo 7.3.0"></head>
<body>
    <div id="layout">
        <transition name="fade">
            <div id="loading" v-show="loading">
                <div id="loading-circle">
                    <h2>LOADING</h2>
                    <p>加载过慢请开启缓存 浏览器默认开启</p>
                    <img src="/images/loading.gif" />
                </div>
            </div>
        </transition>
        <div id="menu" :class="{ hidden: hiddenMenu, 'menu-color': menuColor}">
    <nav id="desktop-menu">
        <a class="title" href="/">
            <span>JXCUSO4的博客</span>
        </a>
        
        <a href="/">
            <i class="fa-solid fa-house fa-fw"></i>
            <span>&ensp;Home</span>
        </a>
        
        <a href="/about">
            <i class="fa-solid fa-id-card fa-fw"></i>
            <span>&ensp;About</span>
        </a>
        
        <a href="/archives">
            <i class="fa-solid fa-box-archive fa-fw"></i>
            <span>&ensp;Archives</span>
        </a>
        
        <a href="/categories">
            <i class="fa-solid fa-bookmark fa-fw"></i>
            <span>&ensp;Categories</span>
        </a>
        
        <a href="/tags">
            <i class="fa-solid fa-tags fa-fw"></i>
            <span>&ensp;Tags</span>
        </a>
        
    </nav>
    <nav id="mobile-menu">
        <div class="title" @click="showMenuItems = !showMenuItems">
            <i class="fa-solid fa-bars fa-fw"></i>
            <span>&emsp;JXCUSO4的博客</span>
        </div>
        <transition name="slide">
            <div class="items" v-show="showMenuItems">
                
                <a href="/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-house fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Home</div>
                    </div>
                </a>
                
                <a href="/about">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-id-card fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">About</div>
                    </div>
                </a>
                
                <a href="/archives">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-box-archive fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Archives</div>
                    </div>
                </a>
                
                <a href="/categories">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-bookmark fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Categories</div>
                    </div>
                </a>
                
                <a href="/tags">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-tags fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Tags</div>
                    </div>
                </a>
                
            </div>
        </transition>
    </nav>
</div>
<transition name="fade">
    <div id="menu-curtain" @click="showMenuItems = !showMenuItems" v-show="showMenuItems"></div>
</transition>

        <div id="main" :class="loading ? 'into-enter-from': 'into-enter-active'">
            <div class="article">
    <div>
        <h1></h1>
    </div>
    <div class="info">
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2024/8/26
        </span>
        
        
    </div>
    
    <div class="content" v-pre>
        <p>title: &gt;-<br>  暑期文献阅读七   Turning Dust into Gold拓展二   </p>
<p>PaD: Program-aided Distillation Can Teach Small Models Reasoning Better than Chain-of-thought Fine-tuning<br>tags:<br>secret: “123456”<br>description: |<br>    Normal _Italic_ <strong>Strong</strong></p>
<h1 id="PaD-Program-aided-Distillation-Can-Teach-Small-Models-Reasoning-Better-than-Chain-of-thought-Fine-tuning"><a href="#PaD-Program-aided-Distillation-Can-Teach-Small-Models-Reasoning-Better-than-Chain-of-thought-Fine-tuning" class="headerlink" title="PaD: Program-aided Distillation Can Teach Small Models Reasoning Better than Chain-of-thought Fine-tuning"></a>PaD: Program-aided Distillation Can Teach Small Models Reasoning Better than Chain-of-thought Fine-tuning</h1><h1 id="why"><a href="#why" class="headerlink" title="why"></a>why</h1><p>先前的工作利用LLMs合成数据，然后微调较小的模型，或对齐预测分布以蒸馏LLMs（Ho et al., 2022; Fu et al., 2023; Hsieh et al., 2023; Wang et al., 2023; Kang et al., 2024）。数据合成范式受链式推理（CoT, Wei et al., 2022）提示的启发。CoT提示引导LLMs生成中间步骤，这显著提高了推理性能。然后，数据合成要求LLMs生成CoT，这些CoT被整理成下游微调数据集。这些CoT数据用于微调较小的模型，从而传递推理能力。然而，LLMs经常产生错误的推理，即它们可能提供正确的最终答案但中间推理步骤不正确（d’Avila Garcez and Lamb, 2020; Frieder et al., 2023）。这种数据中的错误推理会在微调过程中混淆小模型，并阻碍推理能力的学习。此外，现成的强大LLMs是黑箱（例如，ChatGPT），无法访问预测分布。这一特性阻碍了直接对齐LLMs和较小模型之间的分布。</p>
<h1 id="what"><a href="#what" class="headerlink" title="what"></a>what</h1><p>提出了程序辅助蒸馏（PaD），一种利用LLMs生成的合成推理程序来微调较小模型的方法。</p>
<p><strong>三个贡献：</strong></p>
<p>一种新颖的方法，通过合成推理程序并自动过滤错误推理，将LLMs的推理能力蒸馏到较小的模型中。PaD采用自我改进和逐步验证分别进一步学习和指导推理生成。</p>
<p>实验结果表明，通过PaD蒸馏的专业模型在大幅减少模型和数据规模的情况下，性能超过了先前的基线模型，并超越了某些LLMs（例如LLaMA）。</p>
<p>我们进一步发现，PaD缩小了模型的输出空间，使其避免在整个自然语言空间中进行采样，从而比CoT微调实现更低的损失。</p>
<h1 id="how"><a href="#how" class="headerlink" title="how"></a>how</h1><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Knowledge-Distillation-from-Large-Models"><a href="#Knowledge-Distillation-from-Large-Models" class="headerlink" title="Knowledge Distillation from Large Models"></a>Knowledge Distillation from Large Models</h3><h4 id="蒸馏方法分类"><a href="#蒸馏方法分类" class="headerlink" title="蒸馏方法分类"></a>蒸馏方法分类</h4><p>知识蒸馏的方法大致可以分为两类：基于预测的方法和基于中间特征的方法。</p>
<p><strong>基于预测的方法</strong></p>
<ol>
<li><strong>任务特定数据合成</strong>：通过教师模型生成特定任务的数据。这些数据通常包含特定的推理链和预测分布。例如，Ho et al. (2022) 使用教师模型的多步推理输出微调较小的模型。Fu et al. (2023) 则采用链式推理数据和预测分布来专门化小模型。</li>
<li><strong>指令调优框架</strong>：例如，Hsieh et al. (2023) 和 Chan et al. 提取推理链并将这些数据整合到指令调优框架中。Wang et al. (2022) 提出 Self-Instruct 方法，通过自身指导来提高模型性能。</li>
</ol>
<p><strong>基于中间特征的方法</strong></p>
<ol>
<li><strong>统计信息对齐</strong>：例如，Nayak et al. (2019) 和 Chen et al. (2021a) 通过 KL 散度将学生的 softmax 空间与教师模型对齐。</li>
<li><strong>激活记录对齐</strong>：例如，Lopes et al. (2017) 提出最小化教师和学生之间的激活记录距离。</li>
<li><strong>伪数据恢复</strong>：例如，Dream Distillation (Bhardwaj et al., 2019) 使用激活向量作为元数据来恢复伪数据。</li>
<li><strong>共享梯度</strong>：例如，来自公共学习系统的共享梯度也有助于模拟学习过程（Zhu et al., 2019；Geiping et al., 2020；Yin et al., 2021）。</li>
</ol>
<font  color=Salmon  > 上述方法通常依赖于访问教师模型的参数，为了解决这一问题，自蒸馏（Mobahi et al., 2020）提出了一种无需教师模型参数的方法，使用**学生模型自身作为教师进行迭代改进**。</font>

<h3 id="链式推理（Chain-of-Thought-Reasoning）"><a href="#链式推理（Chain-of-Thought-Reasoning）" class="headerlink" title="链式推理（Chain-of-Thought Reasoning）"></a>链式推理（Chain-of-Thought Reasoning）</h3><p><strong>零样本链式推理（Zero-shot CoT）</strong>：</p>
<ul>
<li>由 Kojima et al. (2022) 提出，通过生成和预测最终答案来进行推理，无需预先训练样本。</li>
<li>这种方法利用模型自身的生成能力，直接生成推理过程和最终答案。</li>
</ul>
<p><strong>自一致性（Self-Consistency）</strong>：</p>
<ul>
<li>Wang et al. (2022) 提出，通过对多个 CoT 进行采样，并选择最一致的一个，从而提高推理的准确性。</li>
<li>这种方法通过对多个推理路径进行评估，选择最有可能的正确路径。</li>
</ul>
<p><strong>最少到最多提示（Least-to-Most Prompting）</strong>：</p>
<ul>
<li>Zhou et al. (2023b) 提出，将复杂问题分解为更小的子问题，并迭代地解决这些小问题。</li>
<li>这种方法通过逐步解决子问题，逐渐构建完整的解决方案。</li>
</ul>
<p><strong>PAL（程序辅助推理）</strong>：</p>
<ul>
<li>Gao et al. (2022) 提出，通过将推理形式化为数学公式和代码，来简化链式推理。</li>
<li>这种方法利用程序和公式，使推理过程更加结构化和易于验证。</li>
</ul>
<p><strong>分解推理步骤并进行评估</strong>：</p>
<ul>
<li>Li et al. (2022)、Xie et al. (2023) 和 Ling et al. (2023) 提出，将推理步骤分解，并对每个步骤进行评估，以指导后续的解码。</li>
<li>这种方法通过逐步验证每个推理步骤，确保每一步都是合理的，从而提高整体推理的准确性。</li>
</ul>
<font color=Salmon >我们提出了一种逐步波束搜索方法，以逐步验证推理步骤。主要特点包括：</font>

<ol>
<li><strong>逐步验证</strong>：<ul>
<li>每一步推理都进行验证，确保其正确性。</li>
<li>这种方法通过逐步筛选和优化，每一步都选择最优的推理路径。</li>
</ul>
</li>
<li><strong>程序作为推理格式</strong>：<ul>
<li>选择程序（如代码）作为推理的表达形式。</li>
<li>程序格式更适合小模型，因为它结构化且简洁，便于逐步验证和调整。</li>
</ul>
</li>
</ol>
<h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="从-LLMs-合成数据Synthesizing-Data-From-LLMs"><a href="#从-LLMs-合成数据Synthesizing-Data-From-LLMs" class="headerlink" title="从 LLMs 合成数据Synthesizing Data From LLMs"></a>从 LLMs 合成数据Synthesizing Data From LLMs</h3><p><img src="F:/%E6%9A%91%E6%9C%9F%E5%AE%9E%E9%AA%8C%E5%AE%A4/%E5%8D%9A%E5%AE%A2/source/_posts/%E6%96%B0%E5%BB%BA%E6%96%87%E4%BB%B6%E5%A4%B9/image-20240727144811481.png" alt="image-20240727144811481"></p>
<h4 id="数据合成-Data-Synthesis"><a href="#数据合成-Data-Synthesis" class="headerlink" title="数据合成 Data Synthesis"></a>数据合成 Data Synthesis</h4><p>数据合成是利用大语言模型（LLMs）生成高质量推理数据的过程。通过上下文学习，我们可以在不更新模型参数的情况下，仅基于提供的上下文示例，让 LLMs 生成所需的推理程序。</p>
<p>如图3所示，我们手动构建一个推理程序的问题-答案对，然后将它们与所需的问题结合，从 LLMs 中推导出推理程序。我们将数据合成过程公式化如下：给定一个推理数据集 D 及其问题-答案对样本 $(x_i, y_i) \in D$，我们首先构建上下文示例。每个示例是一个三元组$(\hat{x}_i, \hat{r}_i, \hat{y}_i)$，其中 $\hat{r}$ 表示推理程序。假设有一些上下文示例$C = \{(\hat{x}_1, \hat{r}_1, \hat{y}_1), (\hat{x}_2, \hat{r}_2, \hat{y}_2), …, (\hat{x}_n, \hat{r}_n, \hat{y}_n)\}$，即多个三元组，LLM M应该在上下文示例 C和输入问题 $x_i$的条件下生成相应的推理程序 $r_i$。具体来说，x 表示问题，y 表示答案，r 表示推理程序，C 表示上下文示例。总结来说，我们将数据合成公式化如下：</p>
<p>$r_i = f_M(x_i, C)$</p>
<p>如图所示，将上下文 C作为前缀添加到输入问题 $x_i$。然后，LLM 模拟上下文中的形式提供相应的推理程序$r_i$。此外，我们添加多个示例以获得更精确的推理程序（Wei et al., 2022; Ho et al., 2022）。在数据合成中，不需要 LLMs 输出答案 $y_i$，因为答案可以通过执行推理程序轻松获得。通过这种方法，我们可以获得一个初步的微调数据集 S。</p>
<h4 id="数据过滤-Data-Filtering"><a href="#数据过滤-Data-Filtering" class="headerlink" title="数据过滤 Data Filtering"></a>数据过滤 Data Filtering</h4><p>数据过滤是提高数据集质量的关键步骤。先前的方法中，生成的数据往往包含错误的推理步骤，这会影响小模型的性能。</p>
<ol>
<li><strong>错误识别</strong>：<ul>
<li>利用 Python 解释器自动识别和消除错误样本。</li>
<li>错误可以分为两类：错误答案和语法错误的代码。</li>
</ul>
</li>
<li><strong>改进数据集</strong>：<ul>
<li>通过过滤错误样本，改进微调数据集的质量。</li>
<li>高质量的数据集可以显著提高小模型的性能。</li>
</ul>
</li>
</ol>
<h4 id="数据增强-Augmentation"><a href="#数据增强-Augmentation" class="headerlink" title="数据增强 Augmentation"></a>数据增强 Augmentation</h4><p>由于一个问题可以对应多个解决方案，并且多样化的推理数据可以提高性能（Wang et al., 2022; Ho et al., 2022），我们使用<strong>不同的上下文</strong>为<strong>同一问题</strong>合成不同的推理程序。这种增强提高了数据的多样性。在增强和数据过滤之后，我们获得了一个高质量的数据集 S</p>
<h3 id="微调小模型-Fine-tuning-Small-Models"><a href="#微调小模型-Fine-tuning-Small-Models" class="headerlink" title="微调小模型 Fine-tuning Small Models"></a>微调小模型 Fine-tuning Small Models</h3><p><img src="F:/%E6%9A%91%E6%9C%9F%E5%AE%9E%E9%AA%8C%E5%AE%A4/%E5%8D%9A%E5%AE%A2/source/_posts/%E6%96%B0%E5%BB%BA%E6%96%87%E4%BB%B6%E5%A4%B9/image-20240727151902486.png" alt="image-20240727151902486"></p>
<p><strong>参数初始化</strong>：</p>
<ul>
<li>使用预训练模型来初始化小模型的参数。这是 NLP 中的常见做法，因为预训练模型已经在大规模数据上学习到了丰富的语言表示，能够为下游任务提供良好的起点。</li>
</ul>
<p><strong>数据集准备</strong>：</p>
<ul>
<li>使用经过数据合成和过滤处理后的高质量数据集 SSS。这些数据包含了结构化的推理程序，有助于提升模型的推理能力。</li>
</ul>
<p><strong>模型微调</strong>：</p>
<ul>
<li><p>采用标准的序列到序列（seq2seq）模型对小模型进行微调。seq2seq 模型适用于各种 NLP 任务，特别是那些涉及生成的任务，如翻译和文本生成。</p>
</li>
<li><p>使用交叉熵损失函数来指导模型的训练过程。交叉熵损失衡量了模型预测的概率分布与实际分布之间的差异，目标是最小化这种差异。</p>
<p>$L_{fine-tune}=−∑_{t=1}(/hat{T}<br>)logP(r_{i,t}∣r_{i,&lt;t},xi)$</p>
<p>对于每个时间步 t，损失函数计算模型生成的令牌 $r_{i,t}$的概率 $\log P(r_{i,t} | r_{i,&lt;t}, x_i)$，并累加整个序列的损失。</p>
<p><strong>符号定义</strong>：</p>
<ul>
<li><strong>$t$</strong>：时间步，对应于序列中的令牌位置。</li>
<li><strong>i</strong>：样本索引，对应于数据集 S 中的一个具体样本。</li>
<li><strong>$x_i$</strong>：数据集 S 中的第 i 个问题。</li>
<li><strong>$r_{i,t}$</strong>：在时间步 t模型生成的令牌。</li>
<li><strong>$r_{i,&lt;t}$</strong>：在时间步 t之前生成的所有令牌序列</li>
</ul>
</li>
</ul>
<h3 id="自我改进-Self-Refinement"><a href="#自我改进-Self-Refinement" class="headerlink" title="自我改进 Self-Refinement"></a>自我改进 Self-Refinement</h3><p><img src="F:/%E6%9A%91%E6%9C%9F%E5%AE%9E%E9%AA%8C%E5%AE%A4/%E5%8D%9A%E5%AE%A2/source/_posts/%E6%96%B0%E5%BB%BA%E6%96%87%E4%BB%B6%E5%A4%B9/image-20240727151926868.png" alt="image-20240727151926868"></p>
<p>自我改进的目标是使模型能够从错误反馈中学习，从而改进其推理能力。通过将自我改进能力嵌入小模型中，模型可以在面对错误时自我调整和优化，提高整体推理性能。</p>
<p><strong>多任务学习方法</strong></p>
<ol>
<li><strong>多任务学习设置</strong>：<ul>
<li><strong>推理任务</strong>：模型接收一个问题 x 并生成相应的推理程序 r。</li>
<li><strong>改进任务</strong>：模型接收一个问题 x 和错误代码 r′，并生成改进后的推理程序 r。</li>
</ul>
</li>
<li><strong>任务对齐</strong>：<ul>
<li>推理和改进任务的学习目标是生成准确的推理程序。</li>
<li>通过将这两个任务结合起来，模型在训练过程中可以同时学习如何进行初始推理和如何在遇到错误时进行改进。</li>
</ul>
</li>
</ol>
<p><strong>错误数据集的构建</strong></p>
<p>为了训练模型进行自我改进，我们需要一个包含错误样本和错误反馈的数据集。</p>
<ol>
<li><strong>错误注入</strong>：<ul>
<li>使用 Python 工具从源代码中提取抽象语法树（AST）。</li>
<li>遍历 AST 的各种节点（如变量名和函数定义），并通过对选定节点执行特定操作来注入错误。</li>
<li>例如，更改变量名引发 NameError，在赋值前引用变量引发 UnboundLocalError，错误插入 ‘return’ 语句引发 SyntaxError。</li>
</ul>
</li>
<li><strong>收集错误反馈</strong>：<ul>
<li>将更改后的 AST 转回源代码格式并执行该修改代码。</li>
<li>收集注入错误的错误消息、原始问题的解决方案和准确代码。</li>
<li>通过这种方式，我们获得了一个包含特定类型错误代码样本及其相应错误消息的详细数据集。</li>
</ul>
</li>
</ol>
<h3 id="逐步验证-Step-by-Step-Verification"><a href="#逐步验证-Step-by-Step-Verification" class="headerlink" title="逐步验证 Step-by-Step Verification"></a>逐步验证 Step-by-Step Verification</h3><p><img src="F:/%E6%9A%91%E6%9C%9F%E5%AE%9E%E9%AA%8C%E5%AE%A4/%E5%8D%9A%E5%AE%A2/source/_posts/%E6%96%B0%E5%BB%BA%E6%96%87%E4%BB%B6%E5%A4%B9/image-20240727151943076.png" alt="image-20240727151943076"></p>
<p><strong>生成候选步骤</strong>：</p>
<ul>
<li>在生成过程中，模型会生成多个候选步骤。</li>
<li>对这些候选步骤进行评分，并选择最可信的步骤来继续推理。</li>
</ul>
<p><strong>推理生成过程分解</strong>：</p>
<ul>
<li>将推理生成过程 $P(r|x)$ 分解为一系列自回归步骤 $r = [r_1, \ldots, r_t]$</li>
<li>这种分解允许对每个中间步骤进行单独的验证和优化。</li>
</ul>
<p><strong>评分函数的建立</strong>：</p>
<ul>
<li>使用预训练的推理评分器，通过匹配源文本和候选推理步骤的嵌入来估计语义对齐。</li>
<li>评分函数 $ ψ(ri∣x)=\text{align}(r_i \rightarrow x)$使用余弦相似度作为对齐函数。</li>
</ul>
<p><strong>步骤级别的波束搜索</strong>：</p>
<ul>
<li>引入约束评分函数扩展了传统的标记级波束搜索。</li>
<li>评分函数引导生成过程朝向更可信的步骤。</li>
<li>最终的逐步波束搜索公式为： $E(r_{1:T}) = P_M(r_t | x, r_{1:t-1}) \psi(r_t | x)$, 其中 $P_M(r_t | x, r_{1:t-1})$ 表示单个步骤中标记的联合概率。</li>
</ul>

    </div>
    
    
    
    
    
    
    
</div>

            <footer id="footer">
    <div id="footer-wrap">
        <div>
            &copy;
            2022 - 2024 JXCUSO4的博客
            <span id="footer-icon">
                <i class="fa-solid fa-font-awesome fa-fw"></i>
            </span>
            &commat;JXCUSO4
        </div>
        <div>
            Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp;
            <a target="_blank" rel="noopener" href="https://github.com/theme-particlex/hexo-theme-particlex">ParticleX Theme</a>
        </div>
        
    </div>
</footer>

        </div>
        
        <transition name="fade">
            <div id="preview" ref="preview" v-show="previewShow">
                <img id="preview-content" ref="previewContent" />
            </div>
        </transition>
        
    </div>
    <script src="/js/main.js"></script>
    
    




    
</body>
</html>
